<div>

<p>
Atualmente, um grave problema dentro do tópico de sistemas conversacionais é a falta de atualização dos modelos ao longo do tempo, o que agrava diretamente a degradação do desempenho ao longo do tempo. Essa degradação está relacionada a diversos fatores, sendo usado o nome "concept drift" para definir essa questão. Dentre os diversos fatores relativos a essa degradação, vale citar as mudanças constantes nas condições do mundo real. Caso o modelo não seja atualizado constantemente, os dados do treinamento original ficam obsoletos, resultando em respostas desatualizadas ou, no pior dos casos, irrelevantes, levando o sistema como um todo ao desuso.
</p>
<p>
Uma série de soluções viáveis para enfrentar o problema da falta de atualização de modelos em sistemas conversacionais inclui a implementação de um sistema de feedback ativo, permitindo que os usuários relatem imprecisões e forneçam informações relevantes para melhorias. Além disso, a inserção de dados via internet, por meio de técnicas seguras de web scraping, ajuda a manter os dados o mais atualizado possivel. Por fim, automatizar regras de monitoramento e atualização com base na detecção de "concept drift", pode garantir que o modelo seja constantemente ajustado para se adaptar às mudanças nas condições do mundo real.
</p>
<p>
Eu identifico o tópico de criar um fluxo de atualização constante para sistemas conversacionais muito necessário, apesar de ser trabalhoso. A pior situação para um sistema desse tipo é perder a confiança dos usuários devido a informações erradas; visto isso, deve-se garantir a qualquer custo a confiabilidade dos dados. Apesar da implementação ser trabalhosa, devido a ser um sistema com feedbacks que podem variar, fora o uso de web scraping que é algo perigoso no âmbito da confiabilidade, de maneira geral, após a implementação, a maior preocupação vai ser adaptar o tempo de resposta do sistema às métricas de desempenho, visto que a tendência é que o sistema se mantenha atualizado, evitando o concept drift.
</p>

<p>
Referências:

Joel Jang, Joel_Jang1, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han, Gyeonghun KIM, Stanley Jungkyu Choi, Minjoon Seo.

TOWARDS CONTINUAL KNOWLEDGE LEARNING OF LANGUAGE MODELS. 
 
ICLR 2022 Conference Program Chairs.

28 Jan 2022. 
</p>
</div>